{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10210169,"sourceType":"datasetVersion","datasetId":6303609}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import vit_b_16\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# **Étape 1 : Charger les données**\nclass SpectrogramDataset(Dataset):\n    def __init__(self, data_dir, transform=None, exclude_classes=None):\n        \"\"\"\n        Args:\n            data_dir (str): Répertoire contenant les données organisées par classe.\n            transform (callable, optional): Transformations à appliquer aux images.\n            exclude_classes (list, optional): Liste des noms de classes à exclure.\n        \"\"\"\n        self.data = []\n        self.labels = []\n        self.transform = transform\n        self.classes = sorted([cls for cls in os.listdir(data_dir) if cls not in (exclude_classes or [])])\n\n        for label, genre in enumerate(self.classes):\n            genre_dir = os.path.join(data_dir, genre)\n            for file in os.listdir(genre_dir):\n                if file.endswith('.png'):\n                    file_path = os.path.join(genre_dir, file)\n                    self.data.append(file_path)\n                    self.labels.append(label)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx]).convert('RGB')\n        label = self.labels[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\n\n# Transformations\nimage_size = 224\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontal aléatoire\n    transforms.RandomRotation(degrees=15),   # Rotation aléatoire jusqu'à 15 degrés\n    transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),  # Zoom aléatoire\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Charger les données\ndata_dir = \"/kaggle/input/music-genres/Music_Mel\"\n# Spécifiez la classe à exclure\nexclude_classes = [\"Unknown_MEL\"]\n\n# Initialiser le dataset avec la classe exclue\ndataset = SpectrogramDataset(data_dir, transform=transform, exclude_classes=exclude_classes)\n\n# Division en ensembles\ntrain_data, test_data = train_test_split(range(len(dataset)), test_size=0.3, random_state=42)\nval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n\ntrain_subset = torch.utils.data.Subset(dataset, train_data)\nval_subset = torch.utils.data.Subset(dataset, val_data)\ntest_subset = torch.utils.data.Subset(dataset, test_data)\n\ntrain_loader = DataLoader(train_subset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_subset, batch_size=16, shuffle=False)\n\nprint(f\"Train size: {len(train_subset)}, Val size: {len(val_subset)}, Test size: {len(test_subset)}\")\n\n# **Étape 2 : Modèle préentraîné (ViT ou EfficientNet)**\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Charger un modèle ViT préentraîné\nmodel = vit_b_16(pretrained=True)\n\n# Modifier la tête de classification pour s'adapter au nombre de classes\nmodel.heads = nn.Sequential(\n    nn.Dropout(0.5),  # Dropout pour éviter le surapprentissage\n    nn.Linear(model.heads.head.in_features, len(dataset.classes))  # Adapter le nombre de classes\n)\nmodel = model.to(device)\n\n# Fonction de perte et optimiseur\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\ndef train(model, loader, criterion, optimizer, device):\n    model.train()\n    epoch_loss, correct, total = 0, 0, 0\n\n    for imgs, labels in loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n\n    return epoch_loss / len(loader), correct / total\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    epoch_loss, correct, total = 0, 0, 0\n\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n\n            epoch_loss += loss.item()\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n    return epoch_loss / len(loader), correct / total\n\nclass EarlyStopping:\n    def __init__(self, patience=3, min_delta=0.0):\n        \"\"\"\n        Args:\n            patience (int): Nombre d'époques sans amélioration avant l'arrêt.\n            min_delta (float): Amélioration minimale requise pour être considérée.\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif self.best_loss - val_loss > self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0  # Réinitialiser le compteur si amélioration\n        else:\n            self.counter += 1  # Incrémenter si pas d'amélioration\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n\n# Boucle d'entraînement\nepochs = 250\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\n# Instancier l'early stopping\nearly_stopping = EarlyStopping(patience=3, min_delta=0.01)\n\nfor epoch in range(epochs):\n    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n\n    # Stocker les métriques\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accuracies.append(train_acc)\n    val_accuracies.append(val_acc)\n\n    print(f\"Epoch {epoch+1}/{epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n    # Early stopping\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(\"Early stopping triggered. Stopping training...\")\n        break\n\n# Évaluation finale sur l'ensemble de test\ntest_loss, test_acc = evaluate(model, test_loader, criterion, device)\nprint(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n\n# Prédictions\nall_preds, all_labels = [], []\nmodel.eval()\nwith torch.no_grad():\n    for imgs, labels in test_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        outputs = model(imgs)\n        _, preds = outputs.max(1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Rapport de classification\nprint(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=dataset.classes))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(12, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=dataset.classes, yticklabels=dataset.classes, cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Tracer les courbes de performance\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\")\nplt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\nplt.title(\"Loss Curve\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label=\"Train Accuracy\")\nplt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label=\"Validation Accuracy\")\nplt.title(\"Accuracy Curve\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}