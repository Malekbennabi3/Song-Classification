{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10210169,"sourceType":"datasetVersion","datasetId":6303609}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# **Étape 1 : Charger les données**\nclass SpectrogramDataset(Dataset):\n    def __init__(self, data_dir, transform=None, exclude_classes=None):\n        \"\"\"\n        Args:\n            data_dir (str): Répertoire contenant les données organisées par classe.\n            transform (callable, optional): Transformations à appliquer aux images.\n            exclude_classes (list, optional): Liste des noms de classes à exclure.\n        \"\"\"\n        self.data = []\n        self.labels = []\n        self.transform = transform\n        self.classes = sorted([cls for cls in os.listdir(data_dir) if cls not in (exclude_classes or [])])\n\n        for label, genre in enumerate(self.classes):\n            genre_dir = os.path.join(data_dir, genre)\n            for file in os.listdir(genre_dir):\n                if file.endswith('.png'):\n                    file_path = os.path.join(genre_dir, file)\n                    self.data.append(file_path)\n                    self.labels.append(label)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx]).convert('RGB')\n        label = self.labels[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\n\n# Transformations\nimage_size = 128\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontal aléatoire\n    #transforms.RandomRotation(degrees=15),   # Rotation aléatoire jusqu'à 15 degrés\n    #transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),  # Zoom aléatoire\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Charger les données\ndata_dir = \"/kaggle/input/music-genres/Music_Mel\"\n# Spécifiez la classe à exclure\nexclude_classes = [\"Unknown_MEL\"]\n\n# Initialiser le dataset avec la classe exclue\ndataset = SpectrogramDataset(data_dir, transform=transform, exclude_classes=exclude_classes)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Division en ensembles\ntrain_data, test_data = train_test_split(range(len(dataset)), test_size=0.3, random_state=42)\nval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n\ntrain_subset = torch.utils.data.Subset(dataset, train_data)\nval_subset = torch.utils.data.Subset(dataset, val_data)\ntest_subset = torch.utils.data.Subset(dataset, test_data)\n\ntrain_loader = DataLoader(train_subset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_subset, batch_size=16, shuffle=False)\n\nprint(f\"Train size: {len(train_subset)}, Val size: {len(val_subset)}, Test size: {len(test_subset)}\")\n\n# **Étape 2 : Modèle préentraîné (ViT ou EfficientNet)**\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Modèle préentraîné\nmodel = models.efficientnet_b0(pretrained=True)\n# Modifier la tête de classification pour inclure Dropout\nmodel.classifier[1] = nn.Sequential(\n    nn.Dropout(0.5),  # Ajout de Dropout avec un taux de 50%\n    nn.Linear(model.classifier[1].in_features, len(dataset.classes))\n)\nmodel = model.to(device)\n\n# **Étape 3 : Optimiseur et fonction de perte**\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# **Étape 4 : Entraînement**\ndef train(model, loader, criterion, optimizer, device):\n    model.train()\n    epoch_loss, correct, total = 0, 0, 0\n\n    for imgs, labels in loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n\n    return epoch_loss / len(loader), correct / total\n\ndef evaluate_topk(model, loader, criterion, device, k_values=[1, 3, 5]):\n    \"\"\"\n    Évalue le modèle et calcule les métriques Top-1, Top-3 et Top-5.\n    Args:\n        model: Modèle PyTorch.\n        loader: DataLoader pour les données.\n        criterion: Fonction de perte.\n        device: Appareil (CPU/GPU).\n        k_values: Liste des valeurs de k pour les métriques top-k.\n    Returns:\n        avg_loss: Perte moyenne.\n        topk_accuracies: Dictionnaire contenant les précisions pour chaque k.\n    \"\"\"\n    model.eval()\n    epoch_loss, correct_topk = 0, {k: 0 for k in k_values}\n    total = 0\n\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n\n            epoch_loss += loss.item()\n            total += labels.size(0)\n\n            # Obtenir les indices des k meilleures prédictions\n            for k in k_values:\n                _, topk_preds = torch.topk(outputs, k, dim=1)\n                correct_topk[k] += (topk_preds == labels.view(-1, 1)).sum().item()\n\n    # Moyenne des pertes et précisions Top-k\n    avg_loss = epoch_loss / len(loader)\n    topk_accuracies = {k: correct_topk[k] / total for k in k_values}\n\n    return avg_loss, topk_accuracies\n\nclass EarlyStopping:\n    def __init__(self, patience=3, min_delta=0.0):\n        \"\"\"\n        Args:\n            patience (int): Nombre d'époques sans amélioration avant l'arrêt.\n            min_delta (float): Amélioration minimale requise pour être considérée.\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif self.best_loss - val_loss > self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0  # Réinitialiser le compteur si amélioration\n        else:\n            self.counter += 1  # Incrémenter si pas d'amélioration\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n# Initialisation des listes pour stocker les métriques\ntrain_losses, val_losses = [], []\ntrain_top1, val_top1 = [], []\ntrain_top3, val_top3 = [], []\ntrain_top5, val_top5 = [], []\n\n# Instancier l'early stopping\nearly_stopping = EarlyStopping(patience=3, min_delta=0.01)\n\n# Boucle d'entraînement avec enregistrement des métriques\nepochs = 50\nfor epoch in range(epochs):\n    train_loss, train_acc_topk = evaluate_topk(model, train_loader, criterion, device, k_values=[1, 3, 5])\n    val_loss, val_acc_topk = evaluate_topk(model, val_loader, criterion, device, k_values=[1, 3, 5])\n\n    # Stocker les pertes et précisions Top-k\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_top1.append(train_acc_topk[1])\n    train_top3.append(train_acc_topk[3])\n    train_top5.append(train_acc_topk[5])\n    val_top1.append(val_acc_topk[1])\n    val_top3.append(val_acc_topk[3])\n    val_top5.append(val_acc_topk[5])\n\n    print(f\"Epoch {epoch+1}/{epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Top-1: {train_acc_topk[1]:.4f}, Top-3: {train_acc_topk[3]:.4f}, Top-5: {train_acc_topk[5]:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Top-1: {val_acc_topk[1]:.4f}, Top-3: {val_acc_topk[3]:.4f}, Top-5: {val_acc_topk[5]:.4f}\")\n\n    # Vérifier l'early stopping\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(\"Early stopping triggered. Stopping training...\")\n        break\n\n# **Étape 5 : Évaluation finale sur l'ensemble de test**\ntest_loss, topk_accuracies = evaluate_topk(model, test_loader, criterion, device, k_values=[1, 3, 5])\n\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Top-1 Accuracy: {topk_accuracies[1]:.4f}\")\nprint(f\"Top-3 Accuracy: {topk_accuracies[3]:.4f}\")\nprint(f\"Top-5 Accuracy: {topk_accuracies[5]:.4f}\")\n\n# Prédictions pour la matrice de confusion\nall_preds, all_labels = [], []\nmodel.eval()\nwith torch.no_grad():\n    for imgs, labels in test_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        outputs = model(imgs)\n        _, preds = outputs.max(1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Rapport de classification\nprint(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=dataset.classes))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(12, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=dataset.classes, yticklabels=dataset.classes, cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# **Tracer les courbes de perte et des précisions Top-k**\nplt.figure(figsize=(15, 8))\n\n# Courbe de perte\nplt.subplot(2, 1, 1)\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\nplt.title('Loss Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Courbes des précisions Top-k\nplt.subplot(2, 1, 2)\nplt.plot(range(1, len(train_top1) + 1), train_top1, label='Train Top-1 Accuracy')\nplt.plot(range(1, len(val_top1) + 1), val_top1, label='Validation Top-1 Accuracy')\n\nplt.plot(range(1, len(train_top3) + 1), train_top3, label='Train Top-3 Accuracy')\nplt.plot(range(1, len(val_top3) + 1), val_top3, label='Validation Top-3 Accuracy')\n\nplt.plot(range(1, len(train_top5) + 1), train_top5, label='Train Top-5 Accuracy')\nplt.plot(range(1, len(val_top5) + 1), val_top5, label='Validation Top-5 Accuracy')\n\nplt.title('Top-k Accuracy Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sauvegarde complète du modèle\nfull_model_save_path = \"full_model_efficientnet_b0.pth\"\ntorch.save(model, full_model_save_path)\nprint(f\"Modèle complet sauvegardé à : {full_model_save_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}